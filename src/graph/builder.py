import os
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()

# ëª¨ë“ˆí™”ëœ Agent í•¨ìˆ˜ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from agents.web_search_agent import web_search_agent
from agents.data_analysis_agent import data_analysis_agent
from agents.api_call_agent import api_call_agent
from graph.state import AgentState

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)

# --- 1. Router ì—­í• ì„ í•  LLM í”„ë¡¬í”„íŠ¸ ---
router_prompt = """
ë‹¹ì‹ ì€ ì…ë ¥ëœ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ì‘ì—…ì„ ë¶„ë¥˜í•˜ëŠ” ë§¤ìš° ë‹¨ìˆœí•œ ë¡œë´‡ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ [IF-ELSE ì¡°ê±´ë¬¸]ì„ ìˆœì„œëŒ€ë¡œ í™•ì¸í•˜ê³ , ê°€ì¥ ë¨¼ì € ì¼ì¹˜í•˜ëŠ” ë‹¨ í•˜ë‚˜ì˜ ì‘ì—…ì„ ì„ íƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì ˆëŒ€ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ í•´ì„í•˜ê±°ë‚˜ ì¶”ë¡ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

**[IF-ELSE ì¡°ê±´ë¬¸]**

1.  **IF** ì…ë ¥ í…ìŠ¤íŠ¸ì— ë‹¤ìŒ í‚¤ì›Œë“œ ì¤‘ **í•˜ë‚˜ë¼ë„ í¬í•¨**ë˜ì–´ ìˆëŠ”ê°€?
    - 'ë¶„ì„'
    - 'íŒŒì¼'
    - 'ë°ì´í„°'
    - 'CSV'
    - 'ë°ì´í„°_ë ˆì´ì•„ì›ƒ'
    - 'big_data_set'  (ë’¤ì— ìˆ«ìê°€ ë¶™ì–´ë„ í¬í•¨)
    -> **THEN** ë‹¹ì‹ ì˜ ê²°ì •ì€ **`data_analyzer`** ì´ë‹¤. (ì—¬ê¸°ì„œ ì¦‰ì‹œ ì¤‘ë‹¨)

2.  **ELSE IF** ì…ë ¥ í…ìŠ¤íŠ¸ì— ë‹¤ìŒ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
    - 'ë‰´ìŠ¤'
    - 'íŠ¸ë Œë“œ'
    - 'ê²€ìƒ‰'
    -> **THEN** ë‹¹ì‹ ì˜ ê²°ì •ì€ **`web_searcher`** ì´ë‹¤. (ì—¬ê¸°ì„œ ì¦‰ì‹œ ì¤‘ë‹¨)

3.  **ELSE IF** ì…ë ¥ í…ìŠ¤íŠ¸ì— ë‹¤ìŒ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
    - 'ì •ì±…ìê¸ˆ'
    - 'ëŒ€ì¶œ'
    - 'ì§€ì›ê¸ˆ'
    -> **THEN** ë‹¹ì‹ ì˜ ê²°ì •ì€ **`api_caller`** ì´ë‹¤. (ì—¬ê¸°ì„œ ì¦‰ì‹œ ì¤‘ë‹¨)

4.  **ELSE** (ìœ„ 1, 2, 3ë²ˆ ì¡°ê±´ì— ë‹¨ í•˜ë‚˜ë„ í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ëª¨ë“  ê²½ìš°)
    -> **THEN** ë‹¹ì‹ ì˜ ê²°ì •ì€ **`generate`** ì´ë‹¤.

**[ì…ë ¥ í…ìŠ¤íŠ¸]**
"{query}"

**[ë‹¹ì‹ ì˜ ê²°ì • (ìœ„ ì¡°ê±´ë¬¸ì— ë”°ë¼ ê²°ì •ëœ ë‹¨ í•˜ë‚˜ì˜ ì‘ì—…)]**
"""

# --- 2. ìµœì¢… ë‹µë³€ ìƒì„± ì—­í• ì„ í•  LLM í”„ë¡¬í”„íŠ¸ ---
generation_prompt = """ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ AI ìƒë‹´ê°€ì…ë‹ˆë‹¤.
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©ê³¼ Agentê°€ ì°¾ì•„ì˜¨ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ìƒì„±í•´ì£¼ì„¸ìš”.

[ëŒ€í™” ë‚´ìš© ë° ì •ë³´]
{messages}

[ìµœì¢… ë‹µë³€]
"""

def router_node(state):
    """
    ë©”ì‹œì§€ ì¶œì²˜ë¥¼ í™•ì¸í•˜ì—¬, Agentì˜ ë³´ê³ ëŠ” ì¦‰ì‹œ generateë¡œ ë³´ë‚´ê³ ,
    ì‚¬ìš©ìì˜ ì‹ ê·œ ìš”ì²­ë§Œ LLMì—ê²Œ íŒë‹¨ì„ ë§¡ê¹ë‹ˆë‹¤.
    """
    print("--- ğŸ§‘â€âš–ï¸ Router(Supervisor) ì‹¤í–‰ ---")
    
    messages = state["messages"]
    last_message = messages[-1]

    # 1. (í•µì‹¬!) ë©”ì‹œì§€ ì¶œì²˜ê°€ Agentì¸ì§€ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.
    # HumanMessageì´ì§€ë§Œ, ì´ë¦„ì´ 'user'ê°€ ì•„ë‹ˆë¼ë©´ Agentê°€ ë§Œë“  ë©”ì‹œì§€ì…ë‹ˆë‹¤.
    if isinstance(last_message, HumanMessage) and last_message.name != "user":
        print(f"--- âœ… '{last_message.name}' Agent ì‘ì—… ì™„ë£Œ. ìµœì¢… ë‹µë³€ ìƒì„±ìœ¼ë¡œ ì§í–‰í•©ë‹ˆë‹¤. ---")
        # LLMì—ê²Œ ë¬¼ì–´ë³¼ í•„ìš” ì—†ì´, ì¦‰ì‹œ 'generate' ë…¸ë“œë¡œ ê°€ëŠ” ì§€ë¦„ê¸¸ì„ íƒí•©ë‹ˆë‹¤.
        return {"next": "generate"}

    # 2. ìœ„ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš° (ì¦‰, ì‚¬ìš©ìì˜ ìµœì´ˆ ì§ˆë¬¸ì¸ ê²½ìš°)ì—ë§Œ LLMì„ í˜¸ì¶œí•˜ì—¬ íŒë‹¨í•©ë‹ˆë‹¤.
    valid_destinations = ["data_analyzer", "web_searcher", "api_caller", "generate"]

    prompt = router_prompt.format(query=last_message.content)
    raw_decision = llm.invoke(prompt).content.strip()
    print(f"--- [DEBUG] LLM ì›ë³¸ ì¶œë ¥: '{raw_decision}' ---")

    cleaned_decision = ""
    for node_name in valid_destinations:
        if node_name in raw_decision:
            cleaned_decision = node_name
            break
    
    if not cleaned_decision:
        print(f"--- [ê²½ê³ ] '{raw_decision}'ì—ì„œ ìœ íš¨í•œ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'generate'ë¡œ ê¸°ë³¸ ì„¤ì •í•©ë‹ˆë‹¤. ---")
        cleaned_decision = "generate"
    
    print(f"--- Routerì˜ ìµœì¢… ì •ì œëœ ê²°ì •: '{cleaned_decision}' ---")
    return {"next": cleaned_decision}

def generation_node(state):
    print("--- ğŸ’¬ ìµœì¢… ë‹µë³€ ìƒì„± ---")
    messages = state["messages"]
    
    message_str = "\n".join([f"{msg.type}: {msg.content}" for msg in messages])
    prompt = generation_prompt.format(messages=message_str)
    final_response = llm.invoke(prompt).content.strip()
    
    return {"messages": [AIMessage(content=final_response)]}

# --- 3. ê·¸ë˜í”„ êµ¬ì„± ---
workflow = StateGraph(AgentState)

workflow.add_node("router", router_node)
workflow.add_node("web_searcher", web_search_agent)
workflow.add_node("data_analyzer", data_analysis_agent)
workflow.add_node("api_caller", api_call_agent)
workflow.add_node("generate", generation_node) # ë‹µë³€ ìƒì„± ë…¸ë“œ

workflow.set_entry_point("router") # ì‹œì‘ ë…¸ë“œ ì„¤ì •

workflow.add_conditional_edges(
    "router",
    lambda x: x["next"],
    {
        "web_searcher": "web_searcher",
        "data_analyzer": "data_analyzer",
        "api_caller": "api_caller",
        "generate": "generate",
    },
)

workflow.add_edge("generate", END)
workflow.add_edge("web_searcher", "router")
workflow.add_edge("data_analyzer", "router")
workflow.add_edge("api_caller", "router")

graph = workflow.compile(checkpointer=MemorySaver())
print("âœ… LangGraphê°€ ìµœì¢… êµ¬ì¡°ë¡œ ì„±ê³µì ìœ¼ë¡œ ì»´íŒŒì¼ë˜ì—ˆìŠµë‹ˆë‹¤!")