import os
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()

# ëª¨ë“ˆí™”ëœ Agent í•¨ìˆ˜ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from src.agents.web_search_agent import web_search_agent
from src.agents.data_analysis_agent import data_analysis_agent
from src.agents.api_call_agent import api_call_agent
from src.graph.state import AgentState

# Supervisor ì—­í• ì„ í•  LLM
supervisor_llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)

# ê° Agentì˜ ì—­í• ê³¼ Supervisorì˜ ì„ íƒì§€ë¥¼ ì •ì˜í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ìƒë‹´ ì±—ë´‡ì˜ ì´ê´„ ê´€ë¦¬ì(Supervisor)ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ì „ë¬¸ê°€ì—ê²Œ ì‘ì—…ì„ ë§¡ê¸¸ì§€ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.

1.  **web_searcher**: ìµœì‹  ë‰´ìŠ¤, íŠ¸ë Œë“œ, ì¼ë°˜ì ì¸ ì •ë³´ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ ì„ íƒí•©ë‹ˆë‹¤.
2.  **data_analyzer**: 'ë§¤ì¶œ', 'íŒë§¤ëŸ‰', 'ìˆ˜ìµ' ë“± ì œê³µëœ ë°ì´í„°ì— ëŒ€í•œ ë¶„ì„ì´ë‚˜ í†µê³„ê°€ í•„ìš”í•  ë•Œ ì„ íƒí•©ë‹ˆë‹¤.
3.  **api_caller**: 'ì •ì±…ìê¸ˆ', 'ëŒ€ì¶œ', 'ì§€ì›ê¸ˆ' ë“± êµ¬ì²´ì ì¸ ê¸ˆìœµ ìƒí’ˆ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì„ íƒí•©ë‹ˆë‹¤.
4.  **FINISH**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í•  ìˆ˜ ìˆê±°ë‚˜, ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆì„ ë•Œ ì„ íƒí•©ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{query}"
ë‹¹ì‹ ì˜ ê²°ì • (web_searcher, data_analyzer, api_caller, FINISH ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ):
"""

def supervisor_node(state):
    """
    ì–´ë–¤ Agentë¥¼ í˜¸ì¶œí• ì§€ ê²°ì •í•˜ëŠ” ë…¸ë“œ
    """
    print("--- ğŸ§‘â€âš–ï¸ Supervisor ì‹¤í–‰ ---")
    last_message = state["messages"][-1]
    
    # ë§Œì•½ ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ Agentì˜ ê²°ê³¼ë¬¼ì´ë¼ë©´, ë°”ë¡œ FINISH
    if isinstance(last_message, HumanMessage) and last_message.name != "user":
        print("--- Agent ì‘ì—… ì™„ë£Œ, Supervisorê°€ ìµœì¢… ë‹µë³€ ì¤€ë¹„ ---")
        return {"next": "FINISH"}

    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •
    prompt = system_prompt.format(query=last_message.content)
    response = supervisor_llm.invoke(prompt)
    decision = response.content.strip()
    
    print(f"--- Supervisor ê²°ì •: {decision} ---")
    return {"next": decision}

# ê·¸ë˜í”„ ìƒì„±
workflow = StateGraph(AgentState)

# ë…¸ë“œ(Agent) ì¶”ê°€
workflow.add_node("supervisor", supervisor_node)
workflow.add_node("web_searcher", web_search_agent)
workflow.add_node("data_analyzer", data_analysis_agent)
workflow.add_node("api_caller", api_call_agent)

# ì—£ì§€(ì—°ê²°) ì„¤ì •
workflow.set_entry_point("supervisor")

# Supervisorì˜ ê²°ì •ì— ë”°ë¼ ë¶„ê¸°í•˜ëŠ” ì¡°ê±´ë¶€ ì—£ì§€
workflow.add_conditional_edges(
    "supervisor",
    lambda x: x["next"],
    {
        "web_searcher": "web_searcher",
        "data_analyzer": "data_analyzer",
        "api_caller": "api_caller",
        "FINISH": END,
    },
)

# ê° Agent ì‘ì—…ì´ ëë‚˜ë©´ ë‹¤ì‹œ Supervisorì—ê²Œ ë³´ê³ 
workflow.add_edge("web_searcher", "supervisor")
workflow.add_edge("data_analyzer", "supervisor")
workflow.add_edge("api_caller", "supervisor")

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = workflow.compile()
print("âœ… LangGraphê°€ ì„±ê³µì ìœ¼ë¡œ ì»´íŒŒì¼ë˜ì—ˆìŠµë‹ˆë‹¤!")