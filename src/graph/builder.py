# src/graph/builder.py

from langchain_core.messages import AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv

# ìƒˆë¡œìš´ ìƒíƒœì™€ ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“  'ë„êµ¬(Tool)'ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from graph.state import AgentState
from tools.data_analysis_tool import data_analysis_tool
from tools.web_search_tool import web_search_tool
from tools.api_call_tool import api_caller_tool
from tools.marketing_idea_tool import marketing_idea_generator_tool

# LLM ì´ˆê¸°í™”
load_dotenv() # .env íŒŒì¼ì—ì„œ API í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)

# --- 1. ë„êµ¬(Tool) ë“±ë¡ ---
# ëª¨ë“  ë„êµ¬ë¥¼ ì´ë¦„ê³¼ í•¨ê»˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ Executorê°€ ì‰½ê²Œ ì°¾ì•„ ì“¸ ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤.
tools = {
    "data_analyzer": data_analysis_tool,
    "web_searcher": web_search_tool,
    "api_caller": api_caller_tool,
    "marketing_idea_generator": marketing_idea_generator_tool,
}

# --- 2. ì±—ë´‡ì˜ ìƒˆë¡œìš´ ë‘ë‡Œ: ë…¸ë“œ(Node) ì •ì˜ ---

def planner_node(state: AgentState):
    """ì‚¬ìš©ìžì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ 'ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íš'ë§Œì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("--- ðŸ¤” ìµœê³  ì „ëžµ ì±…ìž„ìž(Planner) í™œë™ ì‹œìž‘ ---")
    
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìžì˜ ìš”ì²­ì„ í•´ê²°í•˜ê¸° ìœ„í•œ, ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë³„ ê³„íšì„ ìƒì„±í•˜ëŠ” AI í”Œëž˜ë„ˆìž…ë‹ˆë‹¤.

**[ë§¤ìš° ì¤‘ìš”í•œ ì¶œë ¥ ê·œì¹™]**
- ë‹¹ì‹ ì˜ ìµœì¢… ì¶œë ¥ë¬¼ì€ **ì˜¤ì§ ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ì‹¤í–‰ ê³„íš ëª©ë¡**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ê° ì¤„ì€ **ë°˜ë“œì‹œ `[Tool: ë„êµ¬ì´ë¦„]` í˜•ì‹ìœ¼ë¡œ ì‹œìž‘**í•´ì•¼ í•©ë‹ˆë‹¤.
- **ì ˆëŒ€ë¡œ** ì„œë¡ , ë¬¸ì œ ì •ì˜, ê°€ì„¤, ìš”ì•½ ë“± ë‹¤ë¥¸ ì–´ë–¤ ì„¤ëª…ë„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ì˜¤ì§ ì‹¤í–‰ ê³„íš ëª©ë¡ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

**[ì˜ˆì‹œ]**
- **ìš”ì²­**: "ìž¬ë°©ë¬¸ìœ¨ 30% ì´í•˜ ë§¤ìž¥ì˜ ìž¬ë°©ë¬¸ìœ¨ì„ ë†’ì¼ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ë¥¼ ì¤˜."
- **ì˜¬ë°”ë¥¸ ì¶œë ¥ (ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ!):**
  1. [Tool: data_analyzer] ìž¬ë°©ë¬¸ ê³ ê°ê³¼ ì²« ë°©ë¬¸ ê³ ê°ì˜ íŠ¹ì„±(ë°©ë¬¸ ìš”ì¼, ì‹œê°„ëŒ€, ì£¼ë¬¸ ë©”ë‰´, ê²°ì œ ê¸ˆì•¡)ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ì°¨ì´ì ì„ ì°¾ì•„ì¤˜.
  2. [Tool: web_searcher] 'ì¹´íŽ˜ ìž¬ë°©ë¬¸ìœ¨ ë†’ì´ëŠ” ìµœì‹  ë§ˆì¼€íŒ… ì „ëžµ'ì„ ê²€ìƒ‰í•´ì„œ ì„±ê³µ ì‚¬ë¡€ 3ê°€ì§€ë¥¼ ìš”ì•½í•´ì¤˜.
  3. [Tool: marketing_idea_generator] ìœ„ 1, 2ë²ˆì˜ ë¶„ì„ ê²°ê³¼ì™€ ì„±ê³µ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ë§¤ìž¥ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ 3ê°€ì§€ë¥¼ ê·¼ê±°ì™€ í•¨ê»˜ ì œì‹œí•´ì¤˜.

**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:**
- **data_analyzer**: ë°ì´í„° íŒŒì¼(ê³ ê° íŠ¹ì„±, ë§¤ì¶œ ë“±)ì„ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.
- **web_searcher**: ìµœì‹  íŠ¸ë Œë“œ, ê²½ìŸì‚¬ ì •ë³´ ë“±ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- **marketing_idea_generator**: ë¶„ì„ëœ ë°ì´í„°ì™€ íŠ¸ë Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

**ì‚¬ìš©ìž ìš”ì²­:** "{state['messages'][-1].content}"

**ìœ„ ê·œì¹™ê³¼ ì˜ˆì‹œì— ë”°ë¼, ì˜¤ì§ ì‹¤í–‰ ê³„íš ëª©ë¡ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”:**
"""
    
    response = llm.invoke(prompt)
    
    # (í•µì‹¬ ìˆ˜ì •!) LLMì˜ ì¶œë ¥ë¬¼ì—ì„œ '[Tool:'ë¡œ ì‹œìž‘í•˜ëŠ” ì¤„ë§Œ 'ê³„íš'ìœ¼ë¡œ ì¸ì •í•©ë‹ˆë‹¤.
    plan = [
        step.strip() for step in response.content.split('\n') 
        if step.strip() and '[Tool:' in step
    ]
    
    print(f"--- ðŸ“ ìˆ˜ë¦½ëœ ìµœì¢… ê³„íš ---\n" + "\n".join(plan))
    return {"plan": plan, "past_steps": []}

def executor_node(state: AgentState):
    """ê³„íšì˜ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ëŠ” 'ì‹¤í–‰ ì „ë¬¸ê°€'"""
    print("--- âš™ï¸ ê³„íš ì‹¤í–‰(Executor) ì‹œìž‘ ---")
    
    step = state["plan"][0]
    
    try:
        tool_name = step.split("[Tool: ")[1].split("]")[0]
        query = step.split("]")[1].strip()
    except IndexError:
        return {"past_steps": state.get("past_steps", []) + [(step, "ì˜¤ë¥˜: ê³„íš í˜•ì‹ì´ ìž˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")]}

    print(f"---  [ì‹¤í–‰] ë„êµ¬: {tool_name} // ì§ˆë¬¸: {query} ---")
    
    if tool_name in tools:
        tool = tools[tool_name]
        try:
            result = tool.invoke(query)
            past_step = (step, str(result))
        except Exception as e:
            # (í•µì‹¬ ìˆ˜ì •!) ìž¡ížŒ ì˜¤ë¥˜ì˜ ë‚´ìš©ì„ í„°ë¯¸ë„ì— ìžì„¸ížˆ ì¶œë ¥í•©ë‹ˆë‹¤.
            print(f"--- ðŸš¨ EXECUTORê°€ ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ê°ì§€: {e} ---") 
            past_step = (step, f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
        return {
            "plan": state["plan"][1:],
            "past_steps": state.get("past_steps", []) + [past_step]
        }
    else:
        return {"past_steps": state.get("past_steps", []) + [(step, "ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ìž…ë‹ˆë‹¤.")]}

def synthesizer_node(state: AgentState):
    """ëª¨ë“  ê·¼ê±°ë¥¼ ì¢…í•©í•˜ì—¬ ì „ë¬¸ ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸ í˜•ì‹ì˜ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("--- âœï¸ ì‹œë‹ˆì–´ ì»¨ì„¤í„´íŠ¸(Synthesizer) ìµœì¢… ë³´ê³ ì„œ ìž‘ì„± ---")

    evidence = "\n\n".join(
        [f"**ì‹¤í–‰ ê³„íš:** {step}\n**ìˆ˜ì§‘ëœ ê·¼ê±°:**\n{result}" for step, result in state.get("past_steps", [])]
    )
    
    prompt = f"""ë‹¹ì‹ ì€ ìˆ˜ì§‘ëœ ëª¨ë“  ê·¼ê±° ìžë£Œë¥¼ ì¢…í•©í•˜ì—¬, ì†Œìƒê³µì¸ì„ ìœ„í•œ ìµœì¢… ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤íŒ… ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ëŠ” ì‹œë‹ˆì–´ ì»¨ì„¤í„´íŠ¸ìž…ë‹ˆë‹¤.
ë‹µë³€ì€ ì•„ëž˜ì˜ **[ë³´ê³ ì„œ í˜•ì‹]**ì„ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•˜ë©°, ëª¨ë“  ë‚´ìš©ì€ ì œê³µëœ **[ìˆ˜ì§‘ëœ ê·¼ê±° ìžë£Œ]**ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.

**[ì‚¬ìš©ìžì˜ ì´ˆê¸° ì§ˆë¬¸]**
{state['messages'][0].content}

**[ìˆ˜ì§‘ëœ ê·¼ê±° ìžë£Œ]**
{evidence}

**[ë³´ê³ ì„œ í˜•ì‹]**
### ðŸ“ ë¬¸ì œì  ì§„ë‹¨
(ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ìž¬ ìƒí™©ê³¼ ê°€ìž¥ í° ë¬¸ì œì ì„ ìš”ì•½í•©ë‹ˆë‹¤.)

### ðŸ’¡ í•´ê²° ë°©ì•ˆ ì œì•ˆ
(ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ìƒì„± ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, êµ¬ì²´ì ì¸ í•´ê²°ì±…ê³¼ ì‹¤í–‰ ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.)

### ðŸ“ˆ ê¸°ëŒ€ íš¨ê³¼
(ì œì‹œí•œ í•´ê²° ë°©ì•ˆì„ ì‹¤í–‰í–ˆì„ ë•Œ ì˜ˆìƒë˜ëŠ” ê¸ì •ì ì¸ ê²°ê³¼ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.)

### ðŸ“š í•µì‹¬ ê·¼ê±° ìžë£Œ
(ë‹µë³€ì˜ ê° ë¶€ë¶„ì´ ì–´ë–¤ ê·¼ê±° ìžë£Œ(ì˜ˆ: [ê·¼ê±°: big_data_set1.csv ë¶„ì„ ê²°ê³¼], [ê·¼ê±°: ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ìƒì„± ê²°ê³¼])ì— ê¸°ë°˜í–ˆëŠ”ì§€ ëª…í™•ížˆ ëª…ì‹œí•©ë‹ˆë‹¤.)

**ìœ„ í˜•ì‹ì— ë§žì¶° ìµœì¢… ì»¨ì„¤íŒ… ë³´ê³ ì„œë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”:**
"""

    response = llm.invoke(prompt)
    return {"messages": [AIMessage(content=response.content)]}

# --- 3. ìƒˆë¡œìš´ ê·¸ëž˜í”„ êµ¬ì„± ---

workflow = StateGraph(AgentState)

# ìƒˆë¡œìš´ ì „ë¬¸ê°€ ë…¸ë“œë“¤ì„ ê·¸ëž˜í”„ì— ì¶”ê°€
workflow.add_node("planner", planner_node)
workflow.add_node("executor", executor_node)
workflow.add_node("synthesizer", synthesizer_node)

# ì‹œìž‘ì ì€ í•­ìƒ 'planner'
workflow.set_entry_point("planner")

# ê° ë…¸ë“œë¥¼ ì—°ê²°
workflow.add_edge("planner", "executor")
workflow.add_edge("synthesizer", END)

# ExecutorëŠ” ì¡°ê±´ë¶€ë¡œ ì—°ê²°: ì‹¤í–‰í•  ê³„íšì´ ë‚¨ì•˜ëŠ”ì§€ í™•ì¸
def should_continue(state: AgentState):
    if state.get("plan"):
        return "executor" # ì•„ì§ ì‹¤í–‰í•  ê³„íšì´ ë‚¨ì•˜ìœ¼ë©´ executorë¡œ ë‹¤ì‹œ ì´ë™ (ë£¨í”„)
    else:
        return "synthesizer" # ê³„íšì´ ëª¨ë‘ ëë‚¬ìœ¼ë©´ synthesizerë¡œ ì´ë™

workflow.add_conditional_edges("executor", should_continue)

# ê·¸ëž˜í”„ ìµœì¢… ì»´íŒŒì¼
graph = workflow.compile(checkpointer=MemorySaver())
print("=========================================//")
print("âœ… 'ê³„íš-ì‹¤í–‰-ì¢…í•©' ëª¨ë¸ë¡œ LangGraphê°€ ì„±ê³µì ìœ¼ë¡œ ì»´íŒŒì¼ë˜ì—ˆìŠµë‹ˆë‹¤!")
# print(">> ê·¸ëž˜í”„ ë…¸ë“œ:", graph.nodes)
print(">> ê·¸ëž˜í”„ ë„êµ¬ ëª©ë¡:", list(tools.keys()))
print("=========================================")
print("ì‹œìž‘ >>")