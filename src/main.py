# src/main_app.py

import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
import uuid
import sys, os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from graph.builder import graph
from utils.logger import log_to_csv

st.set_page_config(page_title="ì†Œìƒê³µì¸ ìƒë‹´ ì±—ë´‡ ğŸ¤–", layout="wide")
st.title("ì†Œìƒê³µì¸ AI ìƒë‹´ ì±—ë´‡ ğŸ¤–")
st.markdown("ë°ì´í„° ë¶„ì„, ì›¹ ê²€ìƒ‰, ì •ì±…ìê¸ˆ ì¡°íšŒ ë“± ë‹¤ì–‘í•œ ì—…ë¬´ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! AI ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")]
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

# --- ì±„íŒ… ê¸°ë¡ í‘œì‹œ ---
for msg in st.session_state.messages:
    # Agentê°€ ìƒì„±í•œ HumanMessageëŠ” í™”ë©´ì— í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    if isinstance(msg, AIMessage) or (isinstance(msg, HumanMessage) and msg.name == 'user'):
        with st.chat_message(msg.type):
            st.markdown(msg.content)

# --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    user_message = HumanMessage(content=prompt, name='user')
    st.session_state.messages.append(user_message)
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        inputs = {"messages": [user_message]}
        config = {"configurable": {"thread_id": st.session_state.thread_id}}

        # Plannerê°€ ì„¸ìš´ ê³„íšì„ í‘œì‹œí•  ë³€ìˆ˜
        plan_steps_str = ""
        # ì‹¤í–‰ëœ ë‹¨ê³„ë¥¼ í‘œì‹œí•  ë³€ìˆ˜
        executed_steps_str = ""

        for chunk in graph.stream(inputs, config=config):
            # plannerê°€ ê³„íšì„ ì„¸ìš°ë©´ í™”ë©´ì— í‘œì‹œ
            if "planner" in chunk:
                plan = chunk["planner"].get("plan", [])
                plan_steps_str = "\n".join([f"â³ {step}" for step in plan])
                message_placeholder.markdown(f"**ìˆ˜ë¦½ëœ ì‘ì—… ê³„íš:**\n{plan_steps_str}")

            # executorê°€ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ë©´ í™”ë©´ ì—…ë°ì´íŠ¸
            if "executor" in chunk:
                past_steps = chunk["executor"].get("past_steps", [])
                executed_steps_str = "\n".join([f"âœ… {step[0]}" for step in past_steps])
                remaining_plan = "\n".join([f"â³ {step}" for step in chunk["executor"].get("plan", [])])
                message_placeholder.markdown(f"**ì‘ì—… ìˆ˜í–‰ í˜„í™©:**\n{executed_steps_str}\n{remaining_plan}")
            
            # synthesizerê°€ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ë©´ í‘œì‹œ
            if "synthesizer" in chunk:
                final_message = chunk["synthesizer"]["messages"][-1]
                if isinstance(final_message, AIMessage):
                    full_response = final_message.content
                    message_placeholder.markdown(full_response)
        
        message_placeholder.markdown(full_response)

    if full_response:
        ai_message = AIMessage(content=full_response)
        st.session_state.messages.append(ai_message)
        # ë¡œê¹…ì€ ì´ì œ ê³„íš ë‹¨ê³„, ê·¼ê±° ë“±ì„ í¬í•¨í•˜ë„ë¡ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì§€ê¸ˆì€ ê°„ë‹¨í•˜ê²Œ ë§ˆì§€ë§‰ ë„êµ¬ ì´ë¦„ë§Œ ê¸°ë¡í•©ë‹ˆë‹¤.
        log_to_csv(user_input=prompt, ai_output=full_response, agent_used="Plan-and-Execute")