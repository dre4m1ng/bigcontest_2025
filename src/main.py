# src/main_app.pyì˜ ìµœì¢… ì™„ì„±ë³¸

import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
import uuid
import sys, os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from graph.builder import graph
from utils.logger import log_to_csv

st.set_page_config(page_title="ì†Œìƒê³µì¸ ìƒë‹´ ì±—ë´‡ ğŸ¤–", layout="wide")
st.title("ì†Œìƒê³µì¸ AI ìƒë‹´ ì±—ë´‡ ğŸ¤–")
st.markdown("ë°ì´í„° ë¶„ì„, ì›¹ ê²€ìƒ‰, ì •ì±…ìê¸ˆ ì¡°íšŒ ë“± ë‹¤ì–‘í•œ ì—…ë¬´ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! AI ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")]
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

# --- ì±„íŒ… ê¸°ë¡ í‘œì‹œ ---
for msg in st.session_state.messages:
    # Agentê°€ ìƒì„±í•œ HumanMessageëŠ” í™”ë©´ì— í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    if isinstance(msg, AIMessage) or (isinstance(msg, HumanMessage) and msg.name == 'user'):
        with st.chat_message(msg.type):
            st.markdown(msg.content)

# --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # (í•µì‹¬ ìˆ˜ì •!) ì‚¬ìš©ìì˜ ì…ë ¥ì„ HumanMessage(name='user')ë¡œ ëª…í™•í•˜ê²Œ ìƒì„±í•©ë‹ˆë‹¤.
    user_message = HumanMessage(content=prompt, name='user')
    st.session_state.messages.append(user_message)
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        agent_used = "N/A"
        status_message = ""

        # (í•µì‹¬ ìˆ˜ì •!) ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ì—ë„ name='user'ê°€ í¬í•¨ëœ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        inputs = {"messages": [user_message]}
        config = {
            "configurable": {"thread_id": st.session_state.thread_id},
            "recursion_limit": 5
        }

        for chunk in graph.stream(inputs, config=config):
            if "web_searcher" in chunk:
                agent_used = "web_searcher"
                status_message = "ğŸ” ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
            elif "data_analyzer" in chunk:
                agent_used = "data_analyzer"
                status_message = "ğŸ“Š ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
            elif "api_caller" in chunk:
                agent_used = "api_caller"
                status_message = "ğŸ“ ì •ì±…ìê¸ˆ ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤..."

            if "generate" in chunk:
                generated_messages = chunk["generate"].get("messages", [])
                if generated_messages and isinstance(generated_messages[-1], AIMessage):
                    full_response = generated_messages[-1].content

            if full_response:
                message_placeholder.markdown(full_response + "â–Œ")
            elif status_message:
                message_placeholder.markdown(status_message)

        message_placeholder.markdown(full_response)

    if full_response:
        ai_message = AIMessage(content=full_response)
        st.session_state.messages.append(ai_message) # ìµœì¢… ë‹µë³€ë§Œ ì„¸ì…˜ì— ì¶”ê°€
        log_to_csv(user_input=prompt, ai_output=full_response, agent_used=agent_used)